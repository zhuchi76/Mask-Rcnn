{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert mask to Detectron2's polygon format\n",
    "def mask_to_polygons(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    polygons = [contour.flatten().tolist() for contour in contours if len(contour.flatten()) > 4]\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading function\n",
    "def get_custom_dataset_dicts(dataset_dir, is_train=True):\n",
    "    dataset_dicts = []\n",
    "    for filename in os.listdir(os.path.join(dataset_dir, \"image\")):\n",
    "        if filename.endswith(\".jpg\"):  # Assuming image files are JPG\n",
    "            image_path = os.path.join(dataset_dir, \"image\", filename)\n",
    "            mask_path = os.path.join(dataset_dir, \"mask\", filename)  # Adjust if needed\n",
    "\n",
    "            height, width = cv2.imread(image_path).shape[:2]\n",
    "            record = {\"file_name\": image_path, \"image_id\": filename, \"height\": height, \"width\": width}\n",
    "\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                continue\n",
    "\n",
    "            polygons = mask_to_polygons(mask)\n",
    "            bbox_array = np.asarray(cv2.boundingRect(mask)).reshape(1, -1)\n",
    "            bbox = BoxMode.convert(bbox_array, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "\n",
    "            objs = [{\"segmentation\": polygons, \"bbox\": bbox, \"bbox_mode\": BoxMode.XYXY_ABS, \"category_id\": 0}]\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "    print(\"Dataset length: \", len(dataset_dicts))\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the dataset\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"my_dataset_\" + d, lambda d=d: get_custom_dataset_dicts(\"training_dataset\", is_train=(d == \"train\")))\n",
    "    MetadataCatalog.get(\"my_dataset_\" + d).set(thing_classes=[\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  60\n",
      "BBox: [[  0   0 640 512]]\n",
      "Segmentation: [[0, 0, 0, 511, 639, 511, 639, 0]]\n",
      "BBox type and shape: <class 'numpy.ndarray'> (1, 4)\n",
      "BBox: [[   0  369 1024  768]]\n",
      "Segmentation: [[1, 369, 1, 401, 0, 402, 0, 767, 101, 767, 102, 766, 1022, 766, 1022, 440, 1023, 439, 1023, 404, 1019, 404, 1018, 403, 932, 403, 931, 402, 810, 402, 809, 403, 803, 403, 802, 402, 771, 402, 770, 401, 739, 401, 738, 400, 700, 400, 699, 399, 684, 399, 683, 398, 668, 398, 667, 397, 620, 397, 619, 398, 612, 398, 611, 397, 564, 397, 563, 396, 517, 396, 516, 395, 465, 395, 464, 394, 380, 394, 379, 393, 325, 393, 324, 392, 312, 392, 311, 391, 294, 391, 293, 390, 293, 389, 295, 387, 295, 386, 301, 380, 302, 380, 304, 378, 312, 378, 313, 379, 314, 378, 324, 378, 325, 379, 327, 379, 328, 380, 330, 380, 331, 381, 333, 381, 334, 380, 356, 380, 357, 379, 384, 379, 385, 378, 463, 378, 465, 376, 466, 376, 467, 375, 468, 375, 469, 374, 470, 374, 445, 374, 444, 373, 429, 373, 428, 372, 412, 372, 411, 371, 385, 371, 384, 372, 372, 372, 371, 373, 368, 373, 367, 372, 310, 372, 309, 373, 304, 373, 303, 372, 274, 372, 273, 371, 273, 370, 163, 370, 162, 369]]\n",
      "BBox type and shape: <class 'numpy.ndarray'> (1, 4)\n",
      "BBox: [[  0   0 536 582]]\n",
      "Segmentation: [[42, 580, 43, 581, 45, 581, 46, 580, 48, 580], [0, 0, 0, 564, 1, 564, 2, 563, 3, 564, 3, 565, 4, 566, 6, 566, 7, 565, 8, 566, 11, 566, 11, 565, 12, 564, 13, 565, 14, 564, 16, 566, 17, 566, 18, 567, 18, 568, 19, 569, 20, 569, 22, 571, 22, 572, 23, 572, 24, 573, 24, 574, 25, 573, 26, 574, 27, 574, 27, 573, 28, 572, 28, 571, 29, 570, 29, 569, 30, 568, 30, 567, 31, 566, 31, 565, 32, 564, 32, 563, 34, 561, 34, 560, 35, 559, 35, 558, 36, 557, 36, 556, 37, 555, 37, 554, 38, 553, 38, 552, 39, 551, 39, 550, 41, 548, 41, 547, 42, 546, 42, 545, 43, 544, 44, 544, 46, 542, 47, 542, 49, 540, 50, 540, 52, 538, 53, 538, 55, 536, 56, 536, 58, 534, 59, 534, 61, 532, 62, 532, 64, 530, 65, 530, 67, 528, 68, 528, 70, 526, 71, 526, 73, 524, 74, 524, 76, 522, 77, 522, 79, 520, 80, 520, 82, 518, 83, 518, 85, 516, 86, 516, 87, 515, 88, 515, 89, 514, 90, 514, 91, 513, 93, 513, 94, 512, 95, 512, 95, 511, 94, 511, 92, 509, 91, 509, 90, 508, 89, 508, 88, 507, 87, 507, 85, 505, 85, 500, 84, 499, 84, 491, 83, 490, 83, 483, 82, 482, 82, 475, 81, 474, 81, 466, 80, 465, 80, 462, 81, 461, 81, 457, 82, 456, 82, 452, 83, 451, 83, 446, 84, 445, 84, 441, 85, 440, 85, 436, 86, 435, 86, 431, 87, 430, 87, 425, 88, 424, 88, 420, 89, 419, 89, 415, 90, 414, 90, 410, 91, 409, 91, 405, 92, 404, 92, 399, 93, 398, 93, 397, 94, 396, 94, 395, 98, 391, 98, 390, 101, 387, 101, 386, 104, 383, 104, 382, 107, 379, 107, 378, 111, 374, 111, 373, 114, 370, 114, 369, 117, 366, 117, 365, 120, 362, 120, 361, 121, 360, 120, 361, 119, 361, 118, 362, 117, 362, 116, 363, 115, 363, 114, 364, 113, 364, 112, 365, 111, 365, 110, 366, 109, 366, 108, 367, 106, 367, 105, 366, 105, 266, 104, 265, 103, 265, 97, 259, 96, 259, 89, 252, 88, 252, 83, 247, 83, 246, 82, 245, 82, 244, 81, 243, 81, 241, 80, 240, 80, 239, 79, 238, 79, 237, 78, 236, 78, 235, 77, 234, 77, 233, 76, 232, 76, 231, 75, 230, 75, 229, 74, 228, 74, 226, 73, 225, 73, 224, 72, 223, 72, 222, 71, 221, 71, 220, 70, 219, 70, 218, 69, 217, 69, 216, 68, 215, 68, 214, 67, 213, 67, 212, 66, 211, 66, 209, 65, 208, 65, 207, 64, 206, 64, 205, 63, 204, 63, 203, 62, 202, 62, 201, 61, 200, 61, 199, 60, 198, 60, 197, 59, 196, 59, 194, 58, 193, 58, 192, 57, 191, 57, 190, 56, 189, 56, 188, 55, 187, 55, 186, 54, 185, 54, 184, 53, 183, 53, 182, 52, 181, 52, 179, 51, 178, 51, 177, 50, 176, 50, 175, 49, 174, 49, 173, 48, 172, 48, 171, 47, 170, 47, 169, 46, 168, 46, 167, 45, 166, 45, 164, 44, 163, 44, 162, 43, 161, 43, 160, 42, 159, 42, 157, 43, 156, 43, 153, 44, 152, 44, 150, 45, 149, 45, 146, 46, 145, 46, 142, 47, 141, 47, 138, 48, 137, 48, 135, 49, 134, 49, 132, 50, 131, 56, 131, 57, 132, 69, 132, 70, 133, 82, 133, 83, 134, 95, 134, 96, 135, 108, 135, 109, 136, 121, 136, 122, 137, 137, 137, 137, 136, 138, 135, 138, 133, 139, 132, 139, 131, 140, 130, 140, 128, 141, 127, 141, 126, 142, 125, 142, 124, 143, 123, 143, 121, 144, 120, 144, 119, 145, 118, 145, 116, 146, 115, 146, 114, 149, 111, 151, 111, 152, 110, 153, 110, 154, 109, 156, 109, 157, 108, 158, 108, 159, 107, 160, 107, 161, 106, 163, 106, 164, 105, 165, 105, 166, 104, 168, 104, 169, 103, 170, 103, 171, 102, 172, 102, 173, 101, 175, 101, 176, 100, 177, 100, 178, 99, 180, 99, 181, 98, 182, 98, 183, 97, 184, 97, 185, 96, 187, 96, 188, 95, 189, 95, 190, 94, 191, 94, 192, 93, 194, 93, 195, 92, 196, 92, 197, 91, 199, 91, 200, 90, 201, 90, 202, 89, 203, 89, 204, 88, 206, 88, 207, 87, 208, 87, 209, 86, 211, 86, 212, 85, 213, 85, 214, 84, 216, 84, 217, 83, 218, 83, 219, 82, 221, 82, 222, 81, 223, 81, 224, 80, 226, 80, 227, 79, 228, 79, 229, 78, 231, 78, 232, 77, 233, 77, 234, 76, 236, 76, 237, 75, 239, 75, 240, 74, 241, 74, 242, 73, 244, 73, 245, 72, 247, 72, 248, 71, 250, 71, 251, 70, 253, 70, 254, 69, 257, 69, 258, 68, 260, 68, 261, 67, 264, 67, 265, 66, 267, 66, 268, 65, 270, 65, 271, 64, 274, 64, 275, 63, 277, 63, 278, 62, 280, 62, 281, 63, 283, 63, 284, 64, 285, 64, 286, 65, 288, 65, 289, 66, 290, 66, 291, 67, 293, 67, 294, 68, 295, 68, 296, 69, 298, 69, 299, 70, 300, 70, 301, 71, 303, 71, 304, 72, 305, 72, 306, 73, 308, 73, 309, 74, 311, 74, 312, 75, 313, 75, 314, 76, 316, 76, 317, 77, 318, 77, 319, 78, 321, 78, 322, 79, 323, 79, 324, 80, 326, 80, 327, 81, 328, 81, 329, 82, 331, 82, 332, 83, 333, 83, 334, 84, 336, 84, 337, 85, 338, 85, 339, 86, 341, 86, 342, 87, 344, 87, 345, 88, 346, 88, 347, 89, 349, 89, 350, 90, 351, 90, 352, 91, 354, 91, 355, 92, 356, 92, 357, 93, 359, 93, 360, 94, 362, 94, 363, 95, 364, 95, 365, 96, 367, 96, 368, 97, 369, 97, 370, 98, 372, 98, 373, 99, 375, 99, 376, 100, 377, 100, 378, 101, 380, 101, 381, 102, 382, 102, 383, 103, 385, 103, 386, 104, 387, 104, 388, 105, 390, 105, 391, 106, 393, 106, 394, 107, 395, 107, 396, 108, 430, 108, 431, 109, 491, 109, 493, 111, 493, 120, 494, 121, 494, 132, 495, 133, 495, 144, 496, 145, 496, 157, 497, 158, 497, 163, 493, 167, 492, 167, 488, 171, 487, 171, 484, 174, 483, 174, 480, 177, 479, 177, 476, 180, 475, 180, 472, 183, 471, 183, 468, 186, 467, 186, 464, 189, 463, 189, 460, 192, 459, 192, 456, 195, 455, 195, 453, 197, 452, 197, 449, 200, 448, 200, 445, 203, 445, 205, 444, 206, 444, 209, 443, 210, 443, 214, 442, 215, 442, 218, 441, 219, 441, 222, 440, 223, 440, 226, 439, 227, 439, 230, 438, 231, 438, 234, 437, 235, 437, 240, 436, 241, 436, 251, 435, 252, 435, 261, 434, 262, 434, 272, 433, 273, 433, 282, 432, 283, 432, 293, 431, 294, 431, 303, 432, 304, 432, 312, 433, 313, 433, 322, 434, 323, 434, 331, 435, 332, 435, 341, 436, 342, 436, 350, 437, 351, 437, 355, 436, 356, 436, 367, 435, 368, 435, 378, 434, 379, 434, 389, 435, 390, 435, 394, 436, 395, 436, 399, 437, 400, 437, 404, 438, 405, 438, 410, 439, 411, 439, 415, 440, 416, 440, 420, 441, 421, 441, 424, 442, 425, 442, 427, 443, 428, 443, 430, 444, 431, 444, 434, 445, 435, 445, 437, 446, 438, 446, 440, 447, 441, 447, 443, 448, 444, 448, 446, 449, 447, 449, 449, 450, 450, 450, 452, 451, 453, 451, 495, 450, 496, 449, 496, 448, 497, 446, 497, 445, 498, 444, 498, 443, 499, 442, 499, 441, 500, 439, 500, 438, 501, 437, 501, 436, 502, 435, 502, 434, 503, 432, 503, 431, 504, 430, 504, 429, 505, 427, 505, 426, 506, 425, 506, 424, 507, 423, 507, 422, 508, 420, 508, 419, 509, 418, 509, 417, 510, 416, 510, 415, 511, 386, 511, 385, 512, 384, 512, 385, 513, 385, 514, 384, 515, 381, 515, 380, 516, 376, 516, 375, 515, 371, 515, 370, 516, 366, 516, 365, 515, 365, 514, 361, 514, 361, 515, 360, 516, 355, 516, 354, 515, 351, 515, 350, 514, 348, 514, 347, 513, 345, 513, 344, 512, 343, 512, 343, 515, 342, 516, 342, 518, 340, 520, 340, 521, 331, 530, 331, 531, 322, 540, 322, 541, 313, 550, 313, 551, 310, 554, 319, 554, 320, 555, 320, 556, 321, 556, 322, 557, 322, 558, 323, 559, 322, 560, 322, 562, 323, 563, 323, 564, 324, 565, 324, 566, 325, 567, 328, 567, 329, 568, 330, 568, 331, 569, 332, 568, 334, 568, 335, 569, 336, 568, 338, 568, 340, 566, 346, 566, 347, 565, 349, 565, 350, 566, 351, 565, 352, 566, 352, 567, 358, 567, 360, 569, 360, 570, 362, 570, 363, 569, 364, 569, 365, 568, 369, 568, 370, 569, 372, 569, 373, 568, 376, 568, 377, 569, 378, 568, 380, 568, 381, 569, 385, 569, 386, 570, 384, 572, 384, 573, 385, 574, 386, 574, 387, 575, 390, 575, 391, 576, 392, 576, 393, 575, 394, 576, 395, 575, 398, 575, 399, 574, 400, 574, 401, 573, 404, 573, 403, 572, 403, 569, 404, 568, 404, 564, 406, 562, 408, 564, 411, 564, 413, 566, 414, 565, 416, 565, 417, 566, 417, 567, 418, 567, 419, 568, 419, 569, 422, 569, 423, 568, 425, 568, 426, 569, 427, 568, 428, 569, 429, 569, 431, 567, 433, 569, 435, 569, 436, 570, 437, 569, 438, 569, 439, 570, 440, 569, 444, 569, 445, 568, 455, 568, 456, 567, 457, 567, 458, 566, 459, 567, 459, 568, 462, 568, 463, 567, 465, 567, 467, 569, 467, 568, 468, 567, 469, 568, 470, 567, 471, 567, 472, 568, 473, 568, 474, 569, 474, 568, 477, 565, 479, 565, 480, 566, 481, 566, 482, 565, 484, 567, 484, 566, 485, 565, 486, 565, 487, 566, 488, 566, 489, 567, 490, 566, 491, 566, 492, 567, 492, 566, 493, 565, 494, 566, 495, 566, 498, 569, 498, 570, 499, 569, 499, 568, 500, 567, 502, 569, 502, 570, 504, 568, 507, 568, 509, 570, 513, 570, 514, 571, 515, 570, 516, 570, 517, 571, 517, 572, 518, 572, 519, 571, 527, 571, 528, 572, 527, 573, 527, 574, 529, 572, 530, 573, 531, 573, 532, 574, 534, 574, 534, 572, 535, 571, 535, 0]]\n",
      "BBox type and shape: <class 'numpy.ndarray'> (1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Visualize Annotations\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "dataset_dicts = get_custom_dataset_dicts(\"training_dataset\", is_train=False)\n",
    "\n",
    "for d in random.sample(dataset_dicts, 1):  # Visualize 1 random images\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"my_dataset_val\"), scale=0.5)\n",
    "\n",
    "    # Debugging: Print bbox and other annotation details\n",
    "    for obj in d[\"annotations\"]:\n",
    "        print(\"BBox:\", obj[\"bbox\"])\n",
    "        print(\"Segmentation:\", obj[\"segmentation\"])\n",
    "        print(\"BBox type and shape:\", type(obj[\"bbox\"]), np.asarray(obj[\"bbox\"]).shape)\n",
    "\n",
    "    # Try drawing only the boxes\n",
    "    out = visualizer.draw_dataset_dict({\"file_name\": d[\"file_name\"], \"annotations\": [{\"segmentation\": obj[\"segmentation\"], \"bbox\": obj[\"bbox\"][0], \"bbox_mode\": obj[\"bbox_mode\"], \"category_id\": obj[\"category_id\"]} for obj in d[\"annotations\"]]})\n",
    "    cv2.imwrite(f'val_image_{d[\"file_name\"]}.jpg', out.get_image()[:, :, ::-1])\n",
    "    cv2.imshow(f'val_image_{d[\"file_name\"]}.jpg', out.get_image()[:, :, ::-1])\n",
    "    # vis = visualizer.draw_dataset_dict(d)\n",
    "    # cv2.imshow('Validation Image', vis.get_image()[:, :, ::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml not available in Model Zoo!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n\u001b[0;32m----> 3\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmerge_from_file(\u001b[43mget_config_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Default configuration\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTRAIN \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_dataset_train\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m      5\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST \u001b[38;5;241m=\u001b[39m ()\n",
      "File \u001b[0;32m~/Mask-Rcnn/detectron2/model_zoo/model_zoo.py:143\u001b[0m, in \u001b[0;36mget_config_file\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m cfg_file \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mresource_filename(\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetectron2.model_zoo\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_path)\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cfg_file):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not available in Model Zoo!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config_path))\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg_file\n",
      "\u001b[0;31mRuntimeError\u001b[0m: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml not available in Model Zoo!"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))  # Default configuration\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Default pretrained weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.002\n",
    "cfg.SOLVER.MAX_ITER = 1000   # Adjust according to your dataset size\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Number of classes\n",
    "cfg.SOLVER.ITER_DISPLAY = 1  # Display metrics every iteration\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000  # Save model every 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.OUTPUT_DIR = \"./output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/05 04:16:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Dataset length:  60\n",
      "\u001b[32m[01/05 04:16:09 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 60 images left.\n",
      "\u001b[32m[01/05 04:16:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/05 04:16:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/05 04:16:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/05 04:16:09 d2.data.common]: \u001b[0mSerializing 60 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/05 04:16:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.27 MiB\n",
      "\u001b[32m[01/05 04:16:09 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/05 04:16:09 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[01/05 04:16:09 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/05 04:16:09 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Model for Evaluation\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # Path to the model weights\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)  # Validation dataset\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05  # Set a threshold for this model\n",
    "\n",
    "# Import Evaluation Modules\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Perform Evaluation\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
